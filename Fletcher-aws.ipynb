{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress, protocol\n",
    "from distributed.protocol import serialize,deserialize\n",
    "import pyarrow as pa\n",
    "import pyfletcher as pf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "client = Client(\"tcp://172.31.84.37:8786\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which executes on the workers\n",
    "def run_on_worker(batch):\n",
    "    print(\"Received data of length: \", len(batch))\n",
    "    platform = pf.Platform(\"aws\", False)\n",
    "\n",
    "    # Create a context\n",
    "    context = pf.Context(platform)\n",
    "\n",
    "    # Initialize the platform\n",
    "    platform.init()\n",
    "\n",
    "    # Prepare the recordbatch\n",
    "    context.queue_record_batch(batch)\n",
    "    context.enable()\n",
    "\n",
    "    # Create UserCore\n",
    "    uc = pf.UserCore(context)\n",
    "\n",
    "    # Reset it\n",
    "    uc.reset()\n",
    "\n",
    "    # Determine size of table\n",
    "    last_index = batch.num_rows\n",
    "    uc.set_range(0, last_index)\n",
    "\n",
    "    # Start the FPGA user function\n",
    "    uc.start()\n",
    "    uc.wait_for_finish(1000)\n",
    "\n",
    "    #Get the sum from UserCore\n",
    "    sum_fpga = uc.get_return(np.dtype(np.int64))\n",
    "    return sum_fpga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_field = pa.field('number', pa.int64(), nullable=False)\n",
    "\n",
    "schema_fields = [number_field]\n",
    "schema = pa.schema(schema_fields)\n",
    "metadata = {b'fletcher_mode': b'read',\n",
    "            b'fletcher_name': b'ExampleBatch'}\n",
    "schema = schema.add_metadata(metadata)\n",
    "\n",
    "NUM_INTEGERS = 1000000\n",
    "\n",
    "#Initialise random array of size NUM_INTEGERS\n",
    "input_arr = np.random.randint(0,1000, NUM_INTEGERS)\n",
    "\n",
    "#Split data evenly amongst all workers\n",
    "num_of_workers = len(client.scheduler_info()[\"workers\"])\n",
    "data_split = []\n",
    "chunk_size = int(NUM_INTEGERS/num_of_workers)\n",
    "start = 0\n",
    "for w in range(num_of_workers):\n",
    "    data_split.append(pa.RecordBatch.from_arrays([pa.array(input_arr[start: start+chunk_size])], schema))        \n",
    "    start += chunk_size\n",
    "\n",
    "#Execute run_on_worker on all workers\n",
    "x = client.map(run_on_worker, data_split)\n",
    "total_sum = 0\n",
    "#Sum individual outputs from workers\n",
    "for o in x:\n",
    "    total_sum += o.result()\n",
    "\n",
    "print(f\"Total sum: {total_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
